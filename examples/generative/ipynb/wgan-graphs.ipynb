{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGEsH3BtlIMv"
      },
      "source": [
        "# WGAN-GP with R-GCN for the generation of small molecular graphs\n",
        "\n",
        "**Author:** [akensert](https://github.com/akensert)<br>\n",
        "**Date created:** 2021/06/30<br>\n",
        "**Last modified:** 2021/06/30<br>\n",
        "**Description:** Complete implementation of WGAN-GP with R-GCN to generate novel molecules."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v90tBb9dlIMx"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this tutorial, we implement a generative model for graphs and use it to generate\n",
        "novel molecules.\n",
        "\n",
        "Motivation: The [development of new drugs](https://en.wikipedia.org/wiki/Drug_development)\n",
        "(molecules) can be extremely time-consuming and costly. The use of deep learning models\n",
        "can alleviate the search for good candidate drugs, by predicting properties of known molecules\n",
        "(e.g., solubility, toxicity, affinity to target protein, etc.). As the number of\n",
        "possible molecules is astronomical, the space in which we search for/explore molecules is\n",
        "just a fraction of the entire space. Therefore, it's arguably desirable to implement\n",
        "generative models that can learn to generate novel molecules (which would otherwise have never been explored).\n",
        "\n",
        "### References (implementation)\n",
        "\n",
        "The implementation in this tutorial is based on/inspired by the\n",
        "[MolGAN paper](https://arxiv.org/abs/1805.11973) and DeepChem's\n",
        "[Basic MolGAN](https://deepchem.readthedocs.io/en/latest/api_reference/models.html#basicmolganmod\n",
        "el).\n",
        "\n",
        "### Further reading (generative models)\n",
        "Recent implementations of generative models for molecular graphs also include\n",
        "[Mol-CycleGAN](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-019-0404-1),\n",
        "[GraphVAE](https://arxiv.org/abs/1802.03480) and\n",
        "[JT-VAE](https://arxiv.org/abs/1802.04364). For more information on generative\n",
        "adverserial networks, see [GAN](https://arxiv.org/abs/1406.2661),\n",
        "[WGAN](https://arxiv.org/abs/1701.07875) and [WGAN-GP](https://arxiv.org/abs/1704.00028)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQoR8583lIMy"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Install RDKit\n",
        "\n",
        "[RDKit](https://www.rdkit.org/) is a collection of cheminformatics and machine-learning\n",
        "software written in C++ and Python. In this tutorial, RDKit is used to conveniently and\n",
        "efficiently transform\n",
        "[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) to\n",
        "molecule objects, and then from those obtain sets of atoms and bonds.\n",
        "\n",
        "SMILES expresses the structure of a given molecule in the form of an ASCII string.\n",
        "The SMILES string is a compact encoding which, for smaller molecules, is relatively\n",
        "human-readable. Encoding molecules as a string both alleviates and facilitates database\n",
        "and/or web searching of a given molecule. RDKit uses algorithms to\n",
        "accurately transform a given SMILES to a molecule object, which can then\n",
        "be used to compute a great number of molecular properties/features.\n",
        "\n",
        "Notice, RDKit is commonly installed via [Conda](https://www.rdkit.org/docs/Install.html).\n",
        "However, thanks to\n",
        "[rdkit_platform_wheels](https://github.com/kuelumbus/rdkit_platform_wheels), rdkit\n",
        "can now (for the sake of this tutorial) be installed easily via pip, as follows:\n",
        "```\n",
        "pip -q install rdkit-pypi\n",
        "```\n",
        "And to allow easy visualization of a molecule objects, Pillow needs to be installed:\n",
        "```\n",
        "pip -q install Pillow\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4QIg5RlIMy"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaPanUo-m2TO",
        "outputId": "4ec8dbc0-6c05-45a8-87a6-0a17980aa63a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨🍰✨ Everything looks OK!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -c conda-forge rdkit -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4axii6Q8nK9R",
        "outputId": "a1e62623-4fe6-4135-cfb2-a5fddfe6cb1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.3\n",
            "    latest version: 25.7.0\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "# All requested packages already installed.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install rdkit-pypi\n",
        "#!pip -q install Pillow"
      ],
      "metadata": {
        "id": "e8XItzrlmbts"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "mol = Chem.MolFromSmiles(\"CCO\")\n",
        "print(\"✅ Parsed molecule:\", mol)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "-l1jW6lnnx7I",
        "outputId": "210f0cbb-26bd-4b32-ded3-620147fab03f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'rdkit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-350654279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMolFromSmiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CCO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Parsed molecule:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'rdkit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -qO- https://micromamba.snakepit.net/api/micromamba/linux-64/latest | tar -xvj bin/micromamba\n",
        "!./bin/micromamba create -y -p /env -c conda-forge rdkit python=3.10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqRRpTwUonBD",
        "outputId": "dfba0d62-a527-43ba-a89c-88d230321ec9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin/micromamba\n",
            "\u001b[?25l\u001b[2K\u001b[0G\u001b[?25h\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "conda-forge/linux-64   1%\n",
            "conda-forge/noarch    ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.2s\n",
            "conda-forge/linux-64  11%\n",
            "conda-forge/noarch    20%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.3s\n",
            "conda-forge/linux-64  20%\n",
            "conda-forge/noarch    40%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.4s\n",
            "conda-forge/linux-64  28%\n",
            "conda-forge/noarch    56%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.5s\n",
            "conda-forge/linux-64  35%\n",
            "conda-forge/noarch    71%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.6s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.7s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.8s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.9s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.0s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    78%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.1s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.2s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.3s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.4s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.5s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.6s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.7s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.8s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 1.9s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "conda-forge/linux-64  38%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    79%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    80%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "conda-forge/linux-64  39%\n",
            "conda-forge/noarch    81%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "conda-forge/linux-64  40%\n",
            "conda-forge/noarch    82%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/noarch                                \n",
            "[+] 5.2s\n",
            "conda-forge/linux-64  50%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "conda-forge/linux-64  68%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "conda-forge/linux-64  75%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "conda-forge/linux-64  77%\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "conda-forge/linux-64  94%\u001b[2K\u001b[1A\u001b[2K\u001b[0Gconda-forge/linux-64                              \n",
            "\u001b[?25h\n",
            "\n",
            "Transaction\n",
            "\n",
            "  Prefix: /env\n",
            "\n",
            "  Updating specs:\n",
            "\n",
            "   - rdkit\n",
            "   - python=3.10\n",
            "\n",
            "\n",
            "  Package                           Version  Build                 Channel          Size\n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "  Install:\n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "  \u001b[32m+ _libgcc_mutex            \u001b[0m           0.1  conda_forge           conda-forge       3kB\n",
            "  \u001b[32m+ _openmp_mutex            \u001b[0m           4.5  2_gnu                 conda-forge      24kB\n",
            "  \u001b[32m+ brotli                   \u001b[0m         1.1.0  hb03c661_4            conda-forge      20kB\n",
            "  \u001b[32m+ brotli-bin               \u001b[0m         1.1.0  hb03c661_4            conda-forge      20kB\n",
            "  \u001b[32m+ bzip2                    \u001b[0m         1.0.8  hda65f42_8            conda-forge     260kB\n",
            "  \u001b[32m+ ca-certificates          \u001b[0m      2025.8.3  hbd8a1cb_0            conda-forge     154kB\n",
            "  \u001b[32m+ cairo                    \u001b[0m        1.18.4  h3394656_0            conda-forge     978kB\n",
            "  \u001b[32m+ charset-normalizer       \u001b[0m         3.4.3  pyhd8ed1ab_0          conda-forge      51kB\n",
            "  \u001b[32m+ contourpy                \u001b[0m         1.3.2  py310h3788b33_0       conda-forge     261kB\n",
            "  \u001b[32m+ cycler                   \u001b[0m        0.12.1  pyhd8ed1ab_1          conda-forge      13kB\n",
            "  \u001b[32m+ cyrus-sasl               \u001b[0m        2.1.28  hd9c7081_0            conda-forge     210kB\n",
            "  \u001b[32m+ font-ttf-dejavu-sans-mono\u001b[0m          2.37  hab24e00_0            conda-forge     397kB\n",
            "  \u001b[32m+ font-ttf-inconsolata     \u001b[0m         3.000  h77eed37_0            conda-forge      97kB\n",
            "  \u001b[32m+ font-ttf-source-code-pro \u001b[0m         2.038  h77eed37_0            conda-forge     701kB\n",
            "  \u001b[32m+ font-ttf-ubuntu          \u001b[0m          0.83  h77eed37_3            conda-forge       2MB\n",
            "  \u001b[32m+ fontconfig               \u001b[0m        2.15.0  h7e30c49_1            conda-forge     266kB\n",
            "  \u001b[32m+ fonts-conda-ecosystem    \u001b[0m             1  0                     conda-forge       4kB\n",
            "  \u001b[32m+ fonts-conda-forge        \u001b[0m             1  0                     conda-forge       4kB\n",
            "  \u001b[32m+ fonttools                \u001b[0m        4.60.0  py310h3406613_0       conda-forge       2MB\n",
            "  \u001b[32m+ freetype                 \u001b[0m        2.14.1  ha770c72_0            conda-forge     173kB\n",
            "  \u001b[32m+ freetype-py              \u001b[0m         2.3.0  pyhd8ed1ab_0          conda-forge      59kB\n",
            "  \u001b[32m+ greenlet                 \u001b[0m         3.2.4  py310hea6c23e_1       conda-forge     218kB\n",
            "  \u001b[32m+ icu                      \u001b[0m          75.1  he02047a_0            conda-forge      12MB\n",
            "  \u001b[32m+ keyutils                 \u001b[0m         1.6.3  hb9d3cd8_0            conda-forge     134kB\n",
            "  \u001b[32m+ kiwisolver               \u001b[0m         1.4.9  py310haaf941d_1       conda-forge      78kB\n",
            "  \u001b[32m+ krb5                     \u001b[0m        1.21.3  h659f571_0            conda-forge       1MB\n",
            "  \u001b[32m+ lcms2                    \u001b[0m          2.17  h717163a_0            conda-forge     248kB\n",
            "  \u001b[32m+ ld_impl_linux-64         \u001b[0m          2.44  ha97dd6f_2            conda-forge     747kB\n",
            "  \u001b[32m+ lerc                     \u001b[0m         4.0.0  h0aef613_1            conda-forge     264kB\n",
            "  \u001b[32m+ libblas                  \u001b[0m         3.9.0  36_h4a7cf45_openblas  conda-forge      17kB\n",
            "  \u001b[32m+ libboost                 \u001b[0m        1.86.0  hed09d94_4            conda-forge       3MB\n",
            "  \u001b[32m+ libboost-python          \u001b[0m        1.86.0  py310hc563356_4       conda-forge     121kB\n",
            "  \u001b[32m+ libbrotlicommon          \u001b[0m         1.1.0  hb03c661_4            conda-forge      69kB\n",
            "  \u001b[32m+ libbrotlidec             \u001b[0m         1.1.0  hb03c661_4            conda-forge      33kB\n",
            "  \u001b[32m+ libbrotlienc             \u001b[0m         1.1.0  hb03c661_4            conda-forge     290kB\n",
            "  \u001b[32m+ libcblas                 \u001b[0m         3.9.0  36_h0358290_openblas  conda-forge      17kB\n",
            "  \u001b[32m+ libdeflate               \u001b[0m          1.24  h86f0d12_0            conda-forge      73kB\n",
            "  \u001b[32m+ libedit                  \u001b[0m  3.1.20250104  pl5321h7949ede_0      conda-forge     135kB\n",
            "  \u001b[32m+ libexpat                 \u001b[0m         2.7.1  hecca717_0            conda-forge      75kB\n",
            "  \u001b[32m+ libffi                   \u001b[0m         3.4.6  h2dba641_1            conda-forge      57kB\n",
            "  \u001b[32m+ libfreetype              \u001b[0m        2.14.1  ha770c72_0            conda-forge       8kB\n",
            "  \u001b[32m+ libfreetype6             \u001b[0m        2.14.1  h73754d4_0            conda-forge     387kB\n",
            "  \u001b[32m+ libgcc                   \u001b[0m        15.1.0  h767d61c_5            conda-forge     824kB\n",
            "  \u001b[32m+ libgcc-ng                \u001b[0m        15.1.0  h69a702a_5            conda-forge      29kB\n",
            "  \u001b[32m+ libgfortran              \u001b[0m        15.1.0  h69a702a_5            conda-forge      29kB\n",
            "  \u001b[32m+ libgfortran5             \u001b[0m        15.1.0  hcea5267_5            conda-forge       2MB\n",
            "  \u001b[32m+ libglib                  \u001b[0m        2.86.0  h1fed272_0            conda-forge       4MB\n",
            "  \u001b[32m+ libgomp                  \u001b[0m        15.1.0  h767d61c_5            conda-forge     447kB\n",
            "  \u001b[32m+ libiconv                 \u001b[0m          1.18  h3b78370_2            conda-forge     790kB\n",
            "  \u001b[32m+ libjpeg-turbo            \u001b[0m         3.1.0  hb9d3cd8_0            conda-forge     629kB\n",
            "  \u001b[32m+ liblapack                \u001b[0m         3.9.0  36_h47877c9_openblas  conda-forge      17kB\n",
            "  \u001b[32m+ liblzma                  \u001b[0m         5.8.1  hb9d3cd8_2            conda-forge     113kB\n",
            "  \u001b[32m+ libnsl                   \u001b[0m         2.0.1  hb9d3cd8_1            conda-forge      34kB\n",
            "  \u001b[32m+ libntlm                  \u001b[0m           1.8  hb9d3cd8_0            conda-forge      33kB\n",
            "  \u001b[32m+ libopenblas              \u001b[0m        0.3.30  pthreads_h94d23a6_2   conda-forge       6MB\n",
            "  \u001b[32m+ libpng                   \u001b[0m        1.6.50  h421ea60_1            conda-forge     317kB\n",
            "  \u001b[32m+ libpq                    \u001b[0m          18.0  h3675c94_0            conda-forge       3MB\n",
            "  \u001b[32m+ librdkit                 \u001b[0m     2025.03.6  h3c5c181_1            conda-forge      10MB\n",
            "  \u001b[32m+ libsqlite                \u001b[0m        3.50.4  h0c1763c_0            conda-forge     933kB\n",
            "  \u001b[32m+ libstdcxx                \u001b[0m        15.1.0  h8f9b012_5            conda-forge       4MB\n",
            "  \u001b[32m+ libstdcxx-ng             \u001b[0m        15.1.0  h4852527_5            conda-forge      29kB\n",
            "  \u001b[32m+ libtiff                  \u001b[0m         4.7.1  h8261f1e_0            conda-forge     437kB\n",
            "  \u001b[32m+ libuuid                  \u001b[0m        2.41.2  he9a06e4_0            conda-forge      37kB\n",
            "  \u001b[32m+ libwebp-base             \u001b[0m         1.6.0  hd42ef1d_0            conda-forge     429kB\n",
            "  \u001b[32m+ libxcb                   \u001b[0m        1.17.0  h8a09558_0            conda-forge     396kB\n",
            "  \u001b[32m+ libxcrypt                \u001b[0m        4.4.36  hd590300_1            conda-forge     100kB\n",
            "  \u001b[32m+ libzlib                  \u001b[0m         1.3.1  hb9d3cd8_2            conda-forge      61kB\n",
            "  \u001b[32m+ matplotlib-base          \u001b[0m        3.10.6  py310hfde16b3_1       conda-forge       7MB\n",
            "  \u001b[32m+ munkres                  \u001b[0m         1.1.4  pyhd8ed1ab_1          conda-forge      16kB\n",
            "  \u001b[32m+ ncurses                  \u001b[0m           6.5  h2d0b736_3            conda-forge     892kB\n",
            "  \u001b[32m+ numpy                    \u001b[0m         2.2.6  py310hefbff90_0       conda-forge       8MB\n",
            "  \u001b[32m+ openjpeg                 \u001b[0m         2.5.4  h55fea9a_0            conda-forge     355kB\n",
            "  \u001b[32m+ openldap                 \u001b[0m        2.6.10  he970967_0            conda-forge     780kB\n",
            "  \u001b[32m+ openssl                  \u001b[0m         3.5.3  h26f9b46_1            conda-forge       3MB\n",
            "  \u001b[32m+ packaging                \u001b[0m          25.0  pyh29332c3_1          conda-forge      62kB\n",
            "  \u001b[32m+ pandas                   \u001b[0m         2.3.2  py310h0158d43_0       conda-forge      13MB\n",
            "  \u001b[32m+ pcre2                    \u001b[0m         10.46  h1321c63_0            conda-forge       1MB\n",
            "  \u001b[32m+ pillow                   \u001b[0m        11.3.0  py310h6557065_3       conda-forge     882kB\n",
            "  \u001b[32m+ pip                      \u001b[0m          25.2  pyh8b19718_0          conda-forge       1MB\n",
            "  \u001b[32m+ pixman                   \u001b[0m        0.46.4  h54a6638_1            conda-forge     451kB\n",
            "  \u001b[32m+ pthread-stubs            \u001b[0m           0.4  hb9d3cd8_1002         conda-forge       8kB\n",
            "  \u001b[32m+ pycairo                  \u001b[0m        1.28.0  py310h8c3e0f7_1       conda-forge     118kB\n",
            "  \u001b[32m+ pyparsing                \u001b[0m         3.2.5  pyhcf101f3_0          conda-forge     104kB\n",
            "  \u001b[32m+ python                   \u001b[0m       3.10.18  hd6af730_0_cpython    conda-forge      25MB\n",
            "  \u001b[32m+ python-dateutil          \u001b[0m   2.9.0.post0  pyhe01879c_2          conda-forge     233kB\n",
            "  \u001b[32m+ python-tzdata            \u001b[0m        2025.2  pyhd8ed1ab_0          conda-forge     144kB\n",
            "  \u001b[32m+ python_abi               \u001b[0m          3.10  8_cp310               conda-forge       7kB\n",
            "  \u001b[32m+ pytz                     \u001b[0m        2025.2  pyhd8ed1ab_0          conda-forge     189kB\n",
            "  \u001b[32m+ qhull                    \u001b[0m        2020.2  h434a139_5            conda-forge     553kB\n",
            "  \u001b[32m+ rdkit                    \u001b[0m     2025.03.6  py310hd71299c_1       conda-forge      20MB\n",
            "  \u001b[32m+ readline                 \u001b[0m           8.2  h8c095d6_2            conda-forge     282kB\n",
            "  \u001b[32m+ reportlab                \u001b[0m         4.4.4  py310h7c4b9e2_0       conda-forge       2MB\n",
            "  \u001b[32m+ rlpycairo                \u001b[0m         0.4.0  pyh6c17108_0          conda-forge      16kB\n",
            "  \u001b[32m+ setuptools               \u001b[0m        80.9.0  pyhff2d567_0          conda-forge     749kB\n",
            "  \u001b[32m+ six                      \u001b[0m        1.17.0  pyhe01879c_1          conda-forge      18kB\n",
            "  \u001b[32m+ sqlalchemy               \u001b[0m        2.0.43  py310h7c4b9e2_0       conda-forge       3MB\n",
            "  \u001b[32m+ tk                       \u001b[0m        8.6.13  noxft_hd72426e_102    conda-forge       3MB\n",
            "  \u001b[32m+ typing-extensions        \u001b[0m        4.15.0  h396c80c_0            conda-forge      91kB\n",
            "  \u001b[32m+ typing_extensions        \u001b[0m        4.15.0  pyhcf101f3_0          conda-forge      52kB\n",
            "  \u001b[32m+ tzdata                   \u001b[0m         2025b  h78e105d_0            conda-forge     123kB\n",
            "  \u001b[32m+ unicodedata2             \u001b[0m        16.0.0  py310h7c4b9e2_1       conda-forge     406kB\n",
            "  \u001b[32m+ wheel                    \u001b[0m        0.45.1  pyhd8ed1ab_1          conda-forge      63kB\n",
            "  \u001b[32m+ xorg-libice              \u001b[0m         1.1.2  hb9d3cd8_0            conda-forge      59kB\n",
            "  \u001b[32m+ xorg-libsm               \u001b[0m         1.2.6  he73a12e_0            conda-forge      28kB\n",
            "  \u001b[32m+ xorg-libx11              \u001b[0m        1.8.12  h4f16b4b_0            conda-forge     836kB\n",
            "  \u001b[32m+ xorg-libxau              \u001b[0m        1.0.12  hb9d3cd8_0            conda-forge      15kB\n",
            "  \u001b[32m+ xorg-libxdmcp            \u001b[0m         1.1.5  hb9d3cd8_0            conda-forge      20kB\n",
            "  \u001b[32m+ xorg-libxext             \u001b[0m         1.3.6  hb9d3cd8_0            conda-forge      50kB\n",
            "  \u001b[32m+ xorg-libxrender          \u001b[0m        0.9.12  hb9d3cd8_0            conda-forge      33kB\n",
            "  \u001b[32m+ zstd                     \u001b[0m         1.5.7  hb8e6e7a_2            conda-forge     568kB\n",
            "\n",
            "  Summary:\n",
            "\n",
            "  Install: 110 packages\n",
            "\n",
            "  Total download: 156MB\n",
            "\n",
            "──────────────────────────────────────────────────────────────────────────────────────────\n",
            "\n",
            "\n",
            "\n",
            "Transaction starting\n",
            "\u001b[?25l\u001b[2K\u001b[0G[+] 0.0s\n",
            "Downloading        5%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 0.1s\n",
            "Downloading  (5)   3%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibrdkit                                             9.9MB @  53.8MB/s  0.1s\n",
            "[+] 0.2s\n",
            "Downloading  (5)  54%\n",
            "Extracting         0%\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpandas                                              12.6MB @  48.0MB/s  0.2s\n",
            "[+] 0.3s\n",
            "Downloading  (5)  69%\n",
            "Extracting   (1)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gicu                                                 12.1MB @  37.5MB/s  0.3s\n",
            "[+] 0.4s\n",
            "Downloading  (5)  76%\n",
            "Extracting   (2)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Grdkit                                               19.8MB @  45.3MB/s  0.4s\n",
            "numpy                                                7.9MB @  29.1MB/s  0.3s\n",
            "[+] 0.5s\n",
            "Downloading  (5)  87%\n",
            "Extracting   (2)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gmatplotlib-base                                      7.5MB @  27.1MB/s  0.3s\n",
            "python                                              25.0MB @  47.5MB/s  0.5s\n",
            "libopenblas                                          5.9MB @  31.2MB/s  0.2s\n",
            "[+] 0.6s\n",
            "Downloading  (5)  88%\n",
            "Extracting   (3)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibstdcxx                                            3.9MB @  15.3MB/s  0.2s\n",
            "libglib                                              4.0MB @  13.4MB/s  0.2s\n",
            "tk                                                   3.3MB @  11.7MB/s  0.2s\n",
            "openssl                                              3.1MB @  10.4MB/s  0.2s\n",
            "[+] 0.7s\n",
            "Downloading  (5)  92%\n",
            "Extracting   (4)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibboost                                             3.0MB @  19.3MB/s  0.1s\n",
            "sqlalchemy                                           2.9MB @  23.5MB/s  0.1s\n",
            "font-ttf-ubuntu                                      1.6MB @   5.5MB/s  0.1s\n",
            "fonttools                                            2.4MB @  23.4MB/s  0.1s\n",
            "[+] 0.8s\n",
            "Downloading  (4)  98%\n",
            "Extracting   (8)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Greportlab                                            2.4MB @  22.8MB/s  0.1s\n",
            "libpq                                                2.8MB @  22.6MB/s  0.1s\n",
            "krb5                                                 1.4MB @  ??.?MB/s  0.1s\n",
            "libgfortran5                                         1.6MB @   6.4MB/s  0.1s\n",
            "cairo                                              978.1kB @   8.5MB/s  0.1s\n",
            "pip                                                  1.2MB @  10.3MB/s  0.1s\n",
            "pcre2                                                1.2MB @   6.8MB/s  0.1s\n",
            "[+] 0.9s\n",
            "Downloading  (5)  97%\n",
            "Extracting  (19)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibsqlite                                          932.6kB @  ??.?MB/s  0.1s\n",
            "libgcc                                             824.2kB @   6.3MB/s  0.1s\n",
            "ncurses                                            891.6kB @  ??.?MB/s  0.1s\n",
            "xorg-libx11                                        835.9kB @  ??.?MB/s  0.1s\n",
            "pillow                                             882.2kB @  ??.?MB/s  0.1s\n",
            "libiconv                                           790.2kB @  ??.?MB/s  0.1s\n",
            "ld_impl_linux-64                                   747.2kB @  ??.?MB/s  0.0s\n",
            "setuptools                                         748.8kB @  ??.?MB/s  0.0s\n",
            "openldap                                           780.3kB @  14.0MB/s  0.1s\n",
            "font-ttf-source-code-pro                           700.8kB @   3.0MB/s  0.1s\n",
            "[+] 1.0s\n",
            "Downloading  (5)  99%\n",
            "Extracting  (32)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibjpeg-turbo                                      628.9kB @  ??.?MB/s  0.0s\n",
            "zstd                                               567.6kB @  ??.?MB/s  0.0s\n",
            "pixman                                             451.0kB @  ??.?MB/s  0.0s\n",
            "qhull                                              552.9kB @   7.3MB/s  0.1s\n",
            "libgomp                                            447.2kB @   3.3MB/s  0.1s\n",
            "libtiff                                            437.2kB @  ??.?MB/s  0.1s\n",
            "libwebp-base                                       429.0kB @  ??.?MB/s  0.0s\n",
            "unicodedata2                                       406.1kB @  ??.?MB/s  0.0s\n",
            "font-ttf-dejavu-sans-mono                          397.4kB @  ??.?MB/s  0.0s\n",
            "libxcb                                             395.9kB @  ??.?MB/s  0.0s\n",
            "[+] 1.1s\n",
            "Downloading  (5)  99%\n",
            "Extracting  (43)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibfreetype6                                       386.7kB @   7.7MB/s  0.1s\n",
            "openjpeg                                           355.4kB @  ??.?MB/s  0.0s\n",
            "libbrotlienc                                       289.7kB @  ??.?MB/s  0.0s\n",
            "libpng                                             317.4kB @  ??.?MB/s  0.0s\n",
            "readline                                           282.5kB @   3.2MB/s  0.1s\n",
            "fontconfig                                         265.6kB @  ??.?MB/s  0.0s\n",
            "lerc                                               264.2kB @  ??.?MB/s  0.0s\n",
            "contourpy                                          261.3kB @  ??.?MB/s  0.0s\n",
            "bzip2                                              260.3kB @  ??.?MB/s  0.0s\n",
            "python-dateutil                                    233.3kB @  ??.?MB/s  0.0s\n",
            "[+] 1.2s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (52)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpytz                                               189.0kB @  ??.?MB/s  0.0s\n",
            "greenlet                                           218.0kB @  ??.?MB/s  0.1s\n",
            "lcms2                                              248.0kB @  ??.?MB/s  0.1s\n",
            "freetype                                           173.1kB @  ??.?MB/s  0.0s\n",
            "cyrus-sasl                                         209.8kB @  ??.?MB/s  0.1s\n",
            "ca-certificates                                    154.4kB @  ??.?MB/s  0.0s\n",
            "libedit                                            134.7kB @   2.7MB/s  0.1s\n",
            "keyutils                                           134.1kB @  ??.?MB/s  0.1s\n",
            "python-tzdata                                      144.2kB @  ??.?MB/s  0.1s\n",
            "tzdata                                             123.0kB @  ??.?MB/s  0.0s\n",
            "[+] 1.3s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (62)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gpyparsing                                          104.0kB @  ??.?MB/s  0.0s\n",
            "libxcrypt                                          100.4kB @  ??.?MB/s  0.0s\n",
            "pycairo                                            117.8kB @  ??.?MB/s  0.1s\n",
            "liblzma                                            112.9kB @  ??.?MB/s  0.1s\n",
            "typing-extensions                                   91.4kB @  ??.?MB/s  0.0s\n",
            "libexpat                                            74.8kB @   1.1MB/s  0.1s\n",
            "font-ttf-inconsolata                                96.5kB @  ??.?MB/s  0.1s\n",
            "kiwisolver                                          77.9kB @  ??.?MB/s  0.1s\n",
            "[+] 1.4s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (70)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibdeflate                                          72.6kB @  ??.?MB/s  0.0s\n",
            "libboost-python                                    120.8kB @  ??.?MB/s  0.2s\n",
            "libbrotlicommon                                     69.3kB @  ??.?MB/s  0.0s\n",
            "packaging                                           62.5kB @   1.1MB/s  0.1s\n",
            "wheel                                               62.9kB @  ??.?MB/s  0.1s\n",
            "xorg-libice                                         58.6kB @  ??.?MB/s  0.0s\n",
            "libzlib                                             61.0kB @  ??.?MB/s  0.0s\n",
            "[+] 1.5s\n",
            "Downloading  (4) 100%\n",
            "Extracting  (77)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Gfreetype-py                                         58.9kB @   1.2MB/s  0.1s\n",
            "libffi                                              57.4kB @  ??.?MB/s  0.0s\n",
            "typing_extensions                                   51.7kB @ 804.3kB/s  0.1s\n",
            "charset-normalizer                                  51.0kB @  ??.?MB/s  0.0s\n",
            "xorg-libxext                                        50.1kB @  ??.?MB/s  0.0s\n",
            "libuuid                                             37.1kB @  ??.?MB/s  0.0s\n",
            "libnsl                                              33.7kB @  ??.?MB/s  0.0s\n",
            "libntlm                                             33.4kB @  ??.?MB/s  0.0s\n",
            "xorg-libxrender                                     33.0kB @  ??.?MB/s  0.0s\n",
            "libbrotlidec                                        33.4kB @ 615.7kB/s  0.1s\n",
            "libgcc-ng                                           29.2kB @  ??.?MB/s  0.0s\n",
            "[+] 1.6s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (88)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibstdcxx-ng                                        29.2kB @ 512.1kB/s  0.1s\n",
            "libgfortran                                         29.2kB @  ??.?MB/s  0.0s\n",
            "_openmp_mutex                                       23.6kB @  ??.?MB/s  0.0s\n",
            "xorg-libxdmcp                                       19.9kB @  ??.?MB/s  0.0s\n",
            "brotli-bin                                          19.6kB @  ??.?MB/s  0.0s\n",
            "xorg-libsm                                          27.6kB @  ??.?MB/s  0.1s\n",
            "brotli                                              19.9kB @  ??.?MB/s  0.0s\n",
            "libblas                                             17.4kB @  ??.?MB/s  0.0s\n",
            "six                                                 18.5kB @  ??.?MB/s  0.1s\n",
            "liblapack                                           17.4kB @  ??.?MB/s  0.0s\n",
            "[+] 1.7s\n",
            "Downloading  (5) 100%\n",
            "Extracting  (98)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0Glibcblas                                            17.4kB @  ??.?MB/s  0.1s\n",
            "cycler                                              13.4kB @  ??.?MB/s  0.0s\n",
            "rlpycairo                                           15.6kB @  ??.?MB/s  0.0s\n",
            "xorg-libxau                                         14.8kB @  ??.?MB/s  0.0s\n",
            "munkres                                             15.9kB @  ??.?MB/s  0.1s\n",
            "pthread-stubs                                        8.3kB @  ??.?MB/s  0.0s\n",
            "fonts-conda-forge                                    4.1kB @  ??.?MB/s  0.0s\n",
            "libfreetype                                          7.7kB @  ??.?MB/s  0.1s\n",
            "python_abi                                           7.0kB @ 129.9kB/s  0.1s\n",
            "fonts-conda-ecosystem                                3.7kB @  ??.?MB/s  0.0s\n",
            "[+] 1.8s\n",
            "Downloading  (1)  100%\n",
            "Extracting  (106)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G_libgcc_mutex                                        2.6kB @  42.6kB/s  0.1s\n",
            "[+] 1.9s\n",
            "Downloading       100%\n",
            "Extracting  (104)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.0s\n",
            "Downloading       100%\n",
            "Extracting  (101)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.1s\n",
            "Downloading       100%\n",
            "Extracting  (100)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.2s\n",
            "Downloading      100%\n",
            "Extracting  (98)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.3s\n",
            "Downloading      100%\n",
            "Extracting  (97)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.4s\n",
            "Downloading      100%\n",
            "Extracting  (97)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.5s\n",
            "Downloading      100%\n",
            "Extracting  (95)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.6s\n",
            "Downloading      100%\n",
            "Extracting  (92)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.7s\n",
            "Downloading      100%\n",
            "Extracting  (90)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.8s\n",
            "Downloading      100%\n",
            "Extracting  (88)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 2.9s\n",
            "Downloading      100%\n",
            "Extracting  (84)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.0s\n",
            "Downloading      100%\n",
            "Extracting  (83)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.1s\n",
            "Downloading      100%\n",
            "Extracting  (81)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.2s\n",
            "Downloading      100%\n",
            "Extracting  (78)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.3s\n",
            "Downloading      100%\n",
            "Extracting  (77)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.4s\n",
            "Downloading      100%\n",
            "Extracting  (74)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.5s\n",
            "Downloading      100%\n",
            "Extracting  (72)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.6s\n",
            "Downloading      100%\n",
            "Extracting  (71)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.7s\n",
            "Downloading      100%\n",
            "Extracting  (69)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.8s\n",
            "Downloading      100%\n",
            "Extracting  (67)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 3.9s\n",
            "Downloading      100%\n",
            "Extracting  (63)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.0s\n",
            "Downloading      100%\n",
            "Extracting  (60)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.1s\n",
            "Downloading      100%\n",
            "Extracting  (55)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.2s\n",
            "Downloading      100%\n",
            "Extracting  (52)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.3s\n",
            "Downloading      100%\n",
            "Extracting  (51)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.4s\n",
            "Downloading      100%\n",
            "Extracting  (50)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.5s\n",
            "Downloading      100%\n",
            "Extracting  (44)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.6s\n",
            "Downloading      100%\n",
            "Extracting  (38)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.7s\n",
            "Downloading      100%\n",
            "Extracting  (34)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.8s\n",
            "Downloading      100%\n",
            "Extracting  (29)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 4.9s\n",
            "Downloading      100%\n",
            "Extracting  (23)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.0s\n",
            "Downloading      100%\n",
            "Extracting  (22)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.1s\n",
            "Downloading      100%\n",
            "Extracting  (19)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.2s\n",
            "Downloading      100%\n",
            "Extracting  (16)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.3s\n",
            "Downloading      100%\n",
            "Extracting  (15)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.4s\n",
            "Downloading      100%\n",
            "Extracting  (14)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.5s\n",
            "Downloading      100%\n",
            "Extracting  (11)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.6s\n",
            "Downloading      100%\n",
            "Extracting  (10)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.7s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.8s\n",
            "Downloading      100%\n",
            "Extracting   (9)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 5.9s\n",
            "Downloading      100%\n",
            "Extracting   (7)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.0s\n",
            "Downloading      100%\n",
            "Extracting   (3)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G[+] 6.1s\n",
            "Downloading      100%\n",
            "Extracting   (1)  ⣾  \u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[0G\u001b[?25hLinking font-ttf-dejavu-sans-mono-2.37-hab24e00_0\n",
            "Linking font-ttf-ubuntu-0.83-h77eed37_3\n",
            "Linking font-ttf-inconsolata-3.000-h77eed37_0\n",
            "Linking font-ttf-source-code-pro-2.038-h77eed37_0\n",
            "Linking python_abi-3.10-8_cp310\n",
            "Linking tzdata-2025b-h78e105d_0\n",
            "Linking ca-certificates-2025.8.3-hbd8a1cb_0\n",
            "Linking fonts-conda-forge-1-0\n",
            "Linking fonts-conda-ecosystem-1-0\n",
            "Linking ld_impl_linux-64-2.44-ha97dd6f_2\n",
            "Linking libgomp-15.1.0-h767d61c_5\n",
            "Linking _libgcc_mutex-0.1-conda_forge\n",
            "Linking _openmp_mutex-4.5-2_gnu\n",
            "Linking libgcc-15.1.0-h767d61c_5\n",
            "Linking libiconv-1.18-h3b78370_2\n",
            "Linking libgfortran5-15.1.0-hcea5267_5\n",
            "Linking libbrotlicommon-1.1.0-hb03c661_4\n",
            "Linking keyutils-1.6.3-hb9d3cd8_0\n",
            "Linking xorg-libxdmcp-1.1.5-hb9d3cd8_0\n",
            "Linking xorg-libxau-1.0.12-hb9d3cd8_0\n",
            "Linking pthread-stubs-0.4-hb9d3cd8_1002\n",
            "Linking libntlm-1.8-hb9d3cd8_0\n",
            "Linking libdeflate-1.24-h86f0d12_0\n",
            "Linking openssl-3.5.3-h26f9b46_1\n",
            "Linking ncurses-6.5-h2d0b736_3\n",
            "Linking libzlib-1.3.1-hb9d3cd8_2\n",
            "Linking libuuid-2.41.2-he9a06e4_0\n",
            "Linking libnsl-2.0.1-hb9d3cd8_1\n",
            "Linking liblzma-5.8.1-hb9d3cd8_2\n",
            "Linking libffi-3.4.6-h2dba641_1\n",
            "Linking bzip2-1.0.8-hda65f42_8\n",
            "Linking libexpat-2.7.1-hecca717_0\n",
            "Linking libwebp-base-1.6.0-hd42ef1d_0\n",
            "Linking libjpeg-turbo-3.1.0-hb9d3cd8_0\n",
            "Linking libstdcxx-15.1.0-h8f9b012_5\n",
            "Linking libgcc-ng-15.1.0-h69a702a_5\n",
            "Linking xorg-libice-1.1.2-hb9d3cd8_0\n",
            "Linking libgfortran-15.1.0-h69a702a_5\n",
            "Linking libbrotlienc-1.1.0-hb03c661_4\n",
            "Linking libbrotlidec-1.1.0-hb03c661_4\n",
            "Linking libxcb-1.17.0-h8a09558_0\n",
            "Linking libedit-3.1.20250104-pl5321h7949ede_0\n",
            "Linking readline-8.2-h8c095d6_2\n",
            "Linking libsqlite-3.50.4-h0c1763c_0\n",
            "Linking libpng-1.6.50-h421ea60_1\n",
            "Linking tk-8.6.13-noxft_hd72426e_102\n",
            "Linking pcre2-10.46-h1321c63_0\n",
            "Linking pixman-0.46.4-h54a6638_1\n",
            "Linking libstdcxx-ng-15.1.0-h4852527_5\n",
            "Linking zstd-1.5.7-hb8e6e7a_2\n",
            "Linking lerc-4.0.0-h0aef613_1\n",
            "Linking libxcrypt-4.4.36-hd590300_1\n",
            "Linking xorg-libsm-1.2.6-he73a12e_0\n",
            "Linking libopenblas-0.3.30-pthreads_h94d23a6_2\n",
            "Linking brotli-bin-1.1.0-hb03c661_4\n",
            "Linking xorg-libx11-1.8.12-h4f16b4b_0\n",
            "Linking libfreetype6-2.14.1-h73754d4_0\n",
            "Linking libglib-2.86.0-h1fed272_0\n",
            "Linking qhull-2020.2-h434a139_5\n",
            "Linking krb5-1.21.3-h659f571_0\n",
            "Linking icu-75.1-he02047a_0\n",
            "Linking libtiff-4.7.1-h8261f1e_0\n",
            "Linking python-3.10.18-hd6af730_0_cpython\n",
            "Linking libblas-3.9.0-36_h4a7cf45_openblas\n",
            "Linking brotli-1.1.0-hb03c661_4\n",
            "Linking xorg-libxrender-0.9.12-hb9d3cd8_0\n",
            "Linking xorg-libxext-1.3.6-hb9d3cd8_0\n",
            "Linking libfreetype-2.14.1-ha770c72_0\n",
            "Linking cyrus-sasl-2.1.28-hd9c7081_0\n",
            "Linking libboost-1.86.0-hed09d94_4\n",
            "Linking openjpeg-2.5.4-h55fea9a_0\n",
            "Linking lcms2-2.17-h717163a_0\n",
            "Linking libcblas-3.9.0-36_h0358290_openblas\n",
            "Linking liblapack-3.9.0-36_h47877c9_openblas\n",
            "Linking freetype-2.14.1-ha770c72_0\n",
            "Linking openldap-2.6.10-he970967_0\n",
            "Linking fontconfig-2.15.0-h7e30c49_1\n",
            "Linking libpq-18.0-h3675c94_0\n",
            "Linking cairo-1.18.4-h3394656_0\n",
            "Linking librdkit-2025.03.6-h3c5c181_1\n",
            "Linking wheel-0.45.1-pyhd8ed1ab_1\n",
            "Linking setuptools-80.9.0-pyhff2d567_0\n",
            "Linking pip-25.2-pyh8b19718_0\n",
            "Linking charset-normalizer-3.4.3-pyhd8ed1ab_0\n",
            "Linking typing_extensions-4.15.0-pyhcf101f3_0\n",
            "Linking six-1.17.0-pyhe01879c_1\n",
            "Linking munkres-1.1.4-pyhd8ed1ab_1\n",
            "Linking pyparsing-3.2.5-pyhcf101f3_0\n",
            "Linking packaging-25.0-pyh29332c3_1\n",
            "Linking cycler-0.12.1-pyhd8ed1ab_1\n",
            "Linking pytz-2025.2-pyhd8ed1ab_0\n",
            "Linking python-tzdata-2025.2-pyhd8ed1ab_0\n",
            "Linking freetype-py-2.3.0-pyhd8ed1ab_0\n",
            "Linking typing-extensions-4.15.0-h396c80c_0\n",
            "Linking python-dateutil-2.9.0.post0-pyhe01879c_2\n",
            "Linking greenlet-3.2.4-py310hea6c23e_1\n",
            "Linking unicodedata2-16.0.0-py310h7c4b9e2_1\n",
            "Linking kiwisolver-1.4.9-py310haaf941d_1\n",
            "Linking pycairo-1.28.0-py310h8c3e0f7_1\n",
            "Linking pillow-11.3.0-py310h6557065_3\n",
            "Linking numpy-2.2.6-py310hefbff90_0\n",
            "Linking sqlalchemy-2.0.43-py310h7c4b9e2_0\n",
            "Linking fonttools-4.60.0-py310h3406613_0\n",
            "Linking contourpy-1.3.2-py310h3788b33_0\n",
            "Linking pandas-2.3.2-py310h0158d43_0\n",
            "Linking libboost-python-1.86.0-py310hc563356_4\n",
            "Linking matplotlib-base-3.10.6-py310hfde16b3_1\n",
            "Linking rlpycairo-0.4.0-pyh6c17108_0\n",
            "Linking reportlab-4.4.4-py310h7c4b9e2_0\n",
            "Linking rdkit-2025.03.6-py310hd71299c_1\n",
            "\n",
            "Transaction finished\n",
            "\n",
            "\n",
            "To activate this environment, use:\n",
            "\n",
            "    micromamba activate /env\n",
            "\n",
            "Or to execute a single command in this environment, use:\n",
            "\n",
            "    micromamba run -p /env mycommand\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/env/lib/python3.10/site-packages\")\n"
      ],
      "metadata": {
        "id": "nJmChgQYopzj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "mol = Chem.MolFromSmiles(\"CCO\")\n",
        "print(\"✅ RDKit working:\", mol)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra-HziIWoq5W",
        "outputId": "efd92270-60d5-44b5-8655-3130d8aeeb04"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ RDKit working: <rdkit.Chem.rdchem.Mol object at 0x7efe0e0669d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bTfPJbS7lIMy"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem.Draw import IPythonConsole, MolsToGridImage\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "RDLogger.DisableLog(\"rdApp.*\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP64rwDIlIMz"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset used in this tutorial is a\n",
        "[quantum mechanics dataset](http://quantum-machine.org/datasets/) (QM9), obtained from\n",
        "[MoleculeNet](http://moleculenet.ai/datasets-1). Although many feature and label columns\n",
        "come with the dataset, we'll only focus on the\n",
        "[SMILES](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system)\n",
        "column. The QM9 dataset is a good first dataset to work with for generating\n",
        "graphs, as the maximum number of heavy (non-hydrogen) atoms found in a molecule is only nine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "xzSKUAimlIMz",
        "outputId": "80d3c7e3-4353-4561-a8cd-51de76fc48d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\n",
            "\u001b[1m29856825/29856825\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "SMILES: Cn1cncc1O\n",
            "Num heavy atoms: 7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7efd80337450>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "csv_path = tf.keras.utils.get_file(\n",
        "    \"qm9.csv\", \"https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/qm9.csv\"\n",
        ")\n",
        "\n",
        "data = []\n",
        "with open(csv_path, \"r\") as f:\n",
        "    for line in f.readlines()[1:]:\n",
        "        data.append(line.split(\",\")[1])\n",
        "\n",
        "# Let's look at a molecule of the dataset\n",
        "smiles = data[1000]\n",
        "print(\"SMILES:\", smiles)\n",
        "molecule = Chem.MolFromSmiles(smiles)\n",
        "print(\"Num heavy atoms:\", molecule.GetNumHeavyAtoms())\n",
        "molecule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBt0-nHElIM0"
      },
      "source": [
        "### Define helper functions\n",
        "These helper functions will help convert SMILES to graphs and graphs to molecule objects.\n",
        "\n",
        "**Representing a molecular graph**. Molecules can naturally be expressed as undirected\n",
        "graphs `G = (V, E)`, where `V` is a set of vertices (atoms), and `E` a set of edges\n",
        "(bonds). As for this implementation, each graph (molecule) will be represented as an\n",
        "adjacency tensor `A`, which encodes existence/non-existence of atom-pairs with their\n",
        "one-hot encoded bond types stretching an extra dimension, and a feature tensor `H`, which\n",
        "for each atom, one-hot encodes its atom type. Notice, as hydrogen atoms can be inferred by\n",
        "RDKit, hydrogen atoms are excluded from `A` and `H` for easier modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "QhvxCwbvlIM0",
        "outputId": "62e1d7a0-fbca-4b6d-f578-d633e209e2d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.RWMol at 0x7efd804fc130>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "atom_mapping = {\n",
        "    \"C\": 0,\n",
        "    0: \"C\",\n",
        "    \"N\": 1,\n",
        "    1: \"N\",\n",
        "    \"O\": 2,\n",
        "    2: \"O\",\n",
        "    \"F\": 3,\n",
        "    3: \"F\",\n",
        "}\n",
        "\n",
        "bond_mapping = {\n",
        "    \"SINGLE\": 0,\n",
        "    0: Chem.BondType.SINGLE,\n",
        "    \"DOUBLE\": 1,\n",
        "    1: Chem.BondType.DOUBLE,\n",
        "    \"TRIPLE\": 2,\n",
        "    2: Chem.BondType.TRIPLE,\n",
        "    \"AROMATIC\": 3,\n",
        "    3: Chem.BondType.AROMATIC,\n",
        "}\n",
        "\n",
        "NUM_ATOMS = 9  # Maximum number of atoms\n",
        "ATOM_DIM = 4 + 1  # Number of atom types\n",
        "BOND_DIM = 4 + 1  # Number of bond types\n",
        "LATENT_DIM = 64  # Size of the latent space\n",
        "\n",
        "\n",
        "def smiles_to_graph(smiles):\n",
        "    # Converts SMILES to molecule object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Initialize adjacency and feature tensor\n",
        "    adjacency = np.zeros((BOND_DIM, NUM_ATOMS, NUM_ATOMS), \"float32\")\n",
        "    features = np.zeros((NUM_ATOMS, ATOM_DIM), \"float32\")\n",
        "\n",
        "    # loop over each atom in molecule\n",
        "    for atom in molecule.GetAtoms():\n",
        "        i = atom.GetIdx()\n",
        "        atom_type = atom_mapping[atom.GetSymbol()]\n",
        "        features[i] = np.eye(ATOM_DIM)[atom_type]\n",
        "        # loop over one-hop neighbors\n",
        "        for neighbor in atom.GetNeighbors():\n",
        "            j = neighbor.GetIdx()\n",
        "            bond = molecule.GetBondBetweenAtoms(i, j)\n",
        "            bond_type_idx = bond_mapping[bond.GetBondType().name]\n",
        "            adjacency[bond_type_idx, [i, j], [j, i]] = 1\n",
        "\n",
        "    # Where no bond, add 1 to last channel (indicating \"non-bond\")\n",
        "    # Notice: channels-first\n",
        "    adjacency[-1, np.sum(adjacency, axis=0) == 0] = 1\n",
        "\n",
        "    # Where no atom, add 1 to last column (indicating \"non-atom\")\n",
        "    features[np.where(np.sum(features, axis=1) == 0)[0], -1] = 1\n",
        "\n",
        "    return adjacency, features\n",
        "\n",
        "\n",
        "def graph_to_molecule(graph):\n",
        "    # Unpack graph\n",
        "    adjacency, features = graph\n",
        "\n",
        "    # RWMol is a molecule object intended to be edited\n",
        "    molecule = Chem.RWMol()\n",
        "\n",
        "    # Remove \"no atoms\" & atoms with no bonds\n",
        "    keep_idx = np.where(\n",
        "        (np.argmax(features, axis=1) != ATOM_DIM - 1)\n",
        "        & (np.sum(adjacency[:-1], axis=(0, 1)) != 0)\n",
        "    )[0]\n",
        "    features = features[keep_idx]\n",
        "    adjacency = adjacency[:, keep_idx, :][:, :, keep_idx]\n",
        "\n",
        "    # Add atoms to molecule\n",
        "    for atom_type_idx in np.argmax(features, axis=1):\n",
        "        atom = Chem.Atom(atom_mapping[atom_type_idx])\n",
        "        _ = molecule.AddAtom(atom)\n",
        "\n",
        "    # Add bonds between atoms in molecule; based on the upper triangles\n",
        "    # of the [symmetric] adjacency tensor\n",
        "    (bonds_ij, atoms_i, atoms_j) = np.where(np.triu(adjacency) == 1)\n",
        "    for (bond_ij, atom_i, atom_j) in zip(bonds_ij, atoms_i, atoms_j):\n",
        "        if atom_i == atom_j or bond_ij == BOND_DIM - 1:\n",
        "            continue\n",
        "        bond_type = bond_mapping[bond_ij]\n",
        "        molecule.AddBond(int(atom_i), int(atom_j), bond_type)\n",
        "\n",
        "    # Sanitize the molecule; for more information on sanitization, see\n",
        "    # https://www.rdkit.org/docs/RDKit_Book.html#molecular-sanitization\n",
        "    flag = Chem.SanitizeMol(molecule, catchErrors=True)\n",
        "    # Let's be strict. If sanitization fails, return None\n",
        "    if flag != Chem.SanitizeFlags.SANITIZE_NONE:\n",
        "        return None\n",
        "\n",
        "    return molecule\n",
        "\n",
        "\n",
        "# Test helper functions\n",
        "graph_to_molecule(smiles_to_graph(smiles))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2yuSI8TlIM1"
      },
      "source": [
        "### Generate training set\n",
        "\n",
        "To save training time, we'll only use a tenth of the QM9 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCJ0ZJwrlIM1",
        "outputId": "fd4541af-ebb7-4593-e08c-5c13c9ab066a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adjacency_tensor.shape = (13389, 5, 9, 9)\n",
            "feature_tensor.shape = (13389, 9, 5)\n"
          ]
        }
      ],
      "source": [
        "adjacency_tensor, feature_tensor = [], []\n",
        "for smiles in data[::10]:\n",
        "    adjacency, features = smiles_to_graph(smiles)\n",
        "    adjacency_tensor.append(adjacency)\n",
        "    feature_tensor.append(features)\n",
        "\n",
        "adjacency_tensor = np.array(adjacency_tensor)\n",
        "feature_tensor = np.array(feature_tensor)\n",
        "\n",
        "print(\"adjacency_tensor.shape =\", adjacency_tensor.shape)\n",
        "print(\"feature_tensor.shape =\", feature_tensor.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c4CDaKplIM1"
      },
      "source": [
        "## Model\n",
        "\n",
        "The idea is to implement a generator network and a discriminator network via WGAN-GP,\n",
        "that will result in a generator network that can generate small novel molecules\n",
        "(small graphs).\n",
        "\n",
        "The generator network needs to be able to map (for each example in the batch) a vector `z`\n",
        "to a 3-D adjacency tensor (`A`) and 2-D feature tensor (`H`). For this, `z` will first be\n",
        "passed through a fully-connected network, for which the output will be further passed\n",
        "through two separate fully-connected networks. Each of these two fully-connected\n",
        "networks will then output (for each example in the batch) a tanh-activated vector\n",
        "followed by a reshape and softmax to match that of a multi-dimensional adjacency/feature\n",
        "tensor.\n",
        "\n",
        "As the discriminator network will receives as input a graph (`A`, `H`) from either the\n",
        "generator or from the training set, we'll need to implement graph convolutional layers,\n",
        "which allows us to operate on graphs. This means that input to the discriminator network\n",
        "will first pass through graph convolutional layers, then an average-pooling layer,\n",
        "and finally a few fully-connected layers. The final output should be a scalar (for each\n",
        "example in the batch) which indicates the \"realness\" of the associated input\n",
        "(in this case a \"fake\" or \"real\" molecule).\n",
        "\n",
        "\n",
        "### Graph generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Ym_PB-3YlIM1",
        "outputId": "ada14411-c5c2-46ff-c4c8-58f4fb64b30b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid dtype: <property object at 0x7efe0c60e3e0>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-554027053.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m generator = GraphGenerator(\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mdense_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-554027053.py\u001b[0m in \u001b[0;36mGraphGenerator\u001b[0;34m(dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Map outputs of previous layer (x) to [continuous] adjacency tensors (x_adjacency)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mx_adjacency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjacency_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mx_adjacency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjacency_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_adjacency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Symmetrify tensors in the last two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36mstandardize_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALLOWED_DTYPES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid dtype: {dtype}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid dtype: <property object at 0x7efe0c60e3e0>"
          ]
        }
      ],
      "source": [
        "\n",
        "def GraphGenerator(\n",
        "    dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape,\n",
        "):\n",
        "    z = keras.layers.Input(shape=(LATENT_DIM,))\n",
        "    # Propagate through one or more densely connected layers\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] adjacency tensors (x_adjacency)\n",
        "    x_adjacency = keras.layers.Dense(tf.math.reduce_prod(adjacency_shape))(x)\n",
        "    x_adjacency = keras.layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "    # Symmetrify tensors in the last two dimensions\n",
        "    x_adjacency = (x_adjacency + tf.transpose(x_adjacency, (0, 1, 3, 2))) / 2\n",
        "    x_adjacency = keras.layers.Softmax(axis=1)(x_adjacency)\n",
        "\n",
        "    # Map outputs of previous layer (x) to [continuous] feature tensors (x_features)\n",
        "    x_features = keras.layers.Dense(tf.math.reduce_prod(feature_shape))(x)\n",
        "    x_features = keras.layers.Reshape(feature_shape)(x_features)\n",
        "    x_features = keras.layers.Softmax(axis=2)(x_features)\n",
        "\n",
        "    return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Generator\")\n",
        "\n",
        "\n",
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "LATENT_DIM   = 32\n",
        "NUM_ATOMS    = 9\n",
        "BOND_DIM     = 4\n",
        "ATOM_DIM     = 5\n",
        "\n",
        "# --- Generator ---\n",
        "def GraphGenerator(\n",
        "    dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape\n",
        "):\n",
        "    z = layers.Input(shape=(latent_dim,))\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Continuous adjacency tensor [BOND_DIM, NUM_ATOMS, NUM_ATOMS]\n",
        "    x_adjacency = layers.Dense(int(tf.reduce_prod(adjacency_shape)))(x)\n",
        "    x_adjacency = layers.Reshape(adjacency_shape)(x_adjacency)\n",
        "\n",
        "    # ✅ Wrap transpose symmetrization inside Lambda\n",
        "    x_adjacency = layers.Lambda(\n",
        "        lambda t: (t + tf.transpose(t, perm=[0, 1, 3, 2])) / 2\n",
        "    )(x_adjacency)\n",
        "\n",
        "    x_adjacency = layers.Softmax(axis=1)(x_adjacency)\n",
        "\n",
        "    # Continuous feature tensor [NUM_ATOMS, ATOM_DIM]\n",
        "    x_features = layers.Dense(int(tf.reduce_prod(feature_shape)))(x)\n",
        "    x_features = layers.Reshape(feature_shape)(x_features)\n",
        "    x_features = layers.Softmax(axis=2)(x_features)\n",
        "\n",
        "    return keras.Model(inputs=z, outputs=[x_adjacency, x_features], name=\"Generator\")\n",
        "\n",
        "\n",
        "# --- Critic (Discriminator) ---\n",
        "def GraphCritic(\n",
        "    dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "    adj_input = layers.Input(shape=adjacency_shape)\n",
        "    feat_input = layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Flatten adjacency and feature tensors\n",
        "    x_adj = layers.Flatten()(adj_input)\n",
        "    x_feat = layers.Flatten()(feat_input)\n",
        "    x = layers.Concatenate()([x_adj, x_feat])\n",
        "\n",
        "    for units in dense_units:\n",
        "        x = layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    out = layers.Dense(1)(x)  # Wasserstein critic output\n",
        "\n",
        "    return keras.Model(inputs=[adj_input, feat_input], outputs=out, name=\"Critic\")\n",
        "\n",
        "\n",
        "# --- Instantiate models ---\n",
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "\n",
        "critic = GraphCritic(\n",
        "    dense_units=[512, 256, 128],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "\n",
        "# --- Summaries ---\n",
        "print(\"✅ Generator Summary\")\n",
        "generator.summary()\n",
        "\n",
        "print(\"\\n✅ Critic Summary\")\n",
        "critic.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wxVRLjEIpsTA",
        "outputId": "e8269a0d-73a8-4589-d480-14010e08ef00"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Generator Summary\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Generator\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Generator\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m4,224\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │     \u001b[38;5;34m33,024\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m131,584\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m324\u001b[0m)       │    \u001b[38;5;34m166,212\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        │     \u001b[38;5;34m23,085\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ reshape_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (\u001b[38;5;33mSoftmax\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">166,212</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,085</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m358,129\u001b[0m (1.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">358,129</span> (1.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m358,129\u001b[0m (1.37 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">358,129</span> (1.37 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Critic Summary\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Critic\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Critic\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m324\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m369\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m189,440\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m131,328\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">324</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">369</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">189,440</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m353,793\u001b[0m (1.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,793</span> (1.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m353,793\u001b[0m (1.35 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">353,793</span> (1.35 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Rfe8O6AlIM2"
      },
      "source": [
        "### Graph discriminator\n",
        "\n",
        "\n",
        "**Graph convolutional layer**. The\n",
        "[relational graph convolutional layers](https://arxiv.org/abs/1703.06103) implements non-linearly transformed\n",
        "neighborhood aggregations. We can define these layers as follows:\n",
        "\n",
        "`H^{l+1} = σ(D^{-1} @ A @ H^{l+1} @ W^{l})`\n",
        "\n",
        "\n",
        "Where `σ` denotes the non-linear transformation (commonly a ReLU activation), `A` the\n",
        "adjacency tensor, `H^{l}` the feature tensor at the `l:th` layer, `D^{-1}` the inverse\n",
        "diagonal degree tensor of `A`, and `W^{l}` the trainable weight tensor at the `l:th`\n",
        "layer. Specifically, for each bond type (relation), the degree tensor expresses, in the\n",
        "diagonal, the number of bonds attached to each atom. Notice, in this tutorial `D^{-1}` is\n",
        "omitted, for two reasons: (1) it's not obvious how to apply this normalization on the\n",
        "continuous adjacency tensors (generated by the generator), and (2) the performance of the\n",
        "WGAN without normalization seems to work just fine. Furthermore, in contrast to the\n",
        "[original paper](https://arxiv.org/abs/1703.06103), no self-loop is defined, as we don't\n",
        "want to train the generator to predict \"self-bonding\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "7nTZgBEQlIM2",
        "outputId": "af9a2b90-02f8-4b7f-9271-1176509d10a2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m5\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │      \u001b[38;5;34m2,560\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mRelationalGraphCo…\u001b[0m │                   │            │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m65,536\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mRelationalGraphCo…\u001b[0m │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m65,536\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mRelationalGraphCo…\u001b[0m │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m65,536\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mRelationalGraphCo…\u001b[0m │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ relational_graph… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m66,048\u001b[0m │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │    \u001b[38;5;34m262,656\u001b[0m │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m513\u001b[0m │ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RelationalGraphCo…</span> │                   │            │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RelationalGraphCo…</span> │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RelationalGraphCo…</span> │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ relational_graph_c… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">65,536</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RelationalGraphCo…</span> │                   │            │ relational_graph… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ relational_graph… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m528,385\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,385</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m528,385\u001b[0m (2.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">528,385</span> (2.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "class RelationalGraphConvLayer(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        units=128,\n",
        "        activation=\"relu\",\n",
        "        use_bias=False,\n",
        "        kernel_initializer=\"glorot_uniform\",\n",
        "        bias_initializer=\"zeros\",\n",
        "        kernel_regularizer=None,\n",
        "        bias_regularizer=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "        self.activation = keras.activations.get(activation)\n",
        "        self.use_bias = use_bias\n",
        "        self.kernel_initializer = keras.initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = keras.initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = keras.regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = keras.regularizers.get(bias_regularizer)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        bond_dim = input_shape[0][1]\n",
        "        atom_dim = input_shape[1][2]\n",
        "\n",
        "        self.kernel = self.add_weight(\n",
        "            shape=(bond_dim, atom_dim, self.units),\n",
        "            initializer=self.kernel_initializer,\n",
        "            regularizer=self.kernel_regularizer,\n",
        "            trainable=True,\n",
        "            name=\"W\",\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\n",
        "                shape=(bond_dim, 1, self.units),\n",
        "                initializer=self.bias_initializer,\n",
        "                regularizer=self.bias_regularizer,\n",
        "                trainable=True,\n",
        "                name=\"b\",\n",
        "                dtype=tf.float32,\n",
        "            )\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        adjacency, features = inputs\n",
        "        # Aggregate information from neighbors\n",
        "        x = tf.matmul(adjacency, features[:, None, :, :])\n",
        "        # Apply linear transformation\n",
        "        x = tf.matmul(x, self.kernel)\n",
        "        if self.use_bias:\n",
        "            x += self.bias\n",
        "        # Reduce bond types dim\n",
        "        x_reduced = tf.reduce_sum(x, axis=1)\n",
        "        # Apply non-linear transformation\n",
        "        return self.activation(x_reduced)\n",
        "\n",
        "\n",
        "def GraphDiscriminator(\n",
        "    gconv_units, dense_units, dropout_rate, adjacency_shape, feature_shape\n",
        "):\n",
        "\n",
        "    adjacency = keras.layers.Input(shape=adjacency_shape)\n",
        "    features = keras.layers.Input(shape=feature_shape)\n",
        "\n",
        "    # Propagate through one or more graph convolutional layers\n",
        "    features_transformed = features\n",
        "    for units in gconv_units:\n",
        "        features_transformed = RelationalGraphConvLayer(units)(\n",
        "            [adjacency, features_transformed]\n",
        "        )\n",
        "\n",
        "    # Reduce 2-D representation of molecule to 1-D\n",
        "    x = keras.layers.GlobalAveragePooling1D()(features_transformed)\n",
        "\n",
        "    # Propagate through one or more densely connected layers\n",
        "    for units in dense_units:\n",
        "        x = keras.layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # For each molecule, output a single scalar value expressing the\n",
        "    # \"realness\" of the inputted molecule\n",
        "    x_out = keras.layers.Dense(1, dtype=\"float32\")(x)\n",
        "\n",
        "    return keras.Model(inputs=[adjacency, features], outputs=x_out)\n",
        "\n",
        "\n",
        "discriminator = GraphDiscriminator(\n",
        "    gconv_units=[128, 128, 128, 128],\n",
        "    dense_units=[512, 512],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "discriminator.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9wqI20LlIM2"
      },
      "source": [
        "### WGAN-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "j4xKGaiUlIM3"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GraphWGAN(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        generator,\n",
        "        discriminator,\n",
        "        discriminator_steps=1,\n",
        "        generator_steps=1,\n",
        "        gp_weight=10,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.generator = generator\n",
        "        self.discriminator = discriminator\n",
        "        self.discriminator_steps = discriminator_steps\n",
        "        self.generator_steps = generator_steps\n",
        "        self.gp_weight = gp_weight\n",
        "        self.latent_dim = self.generator.input_shape[-1]\n",
        "\n",
        "    def compile(self, optimizer_generator, optimizer_discriminator, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.optimizer_generator = optimizer_generator\n",
        "        self.optimizer_discriminator = optimizer_discriminator\n",
        "        self.metric_generator = keras.metrics.Mean(name=\"loss_gen\")\n",
        "        self.metric_discriminator = keras.metrics.Mean(name=\"loss_dis\")\n",
        "\n",
        "    def train_step(self, inputs):\n",
        "\n",
        "        if isinstance(inputs[0], tuple):\n",
        "            inputs = inputs[0]\n",
        "\n",
        "        graph_real = inputs\n",
        "\n",
        "        self.batch_size = tf.shape(inputs[0])[0]\n",
        "\n",
        "        # Train the discriminator for one or more steps\n",
        "        for _ in range(self.discriminator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_discriminator(graph_real, graph_generated)\n",
        "\n",
        "            grads = tape.gradient(loss, self.discriminator.trainable_weights)\n",
        "            self.optimizer_discriminator.apply_gradients(\n",
        "                zip(grads, self.discriminator.trainable_weights)\n",
        "            )\n",
        "            self.metric_discriminator.update_state(loss)\n",
        "\n",
        "        # Train the generator for one or more steps\n",
        "        for _ in range(self.generator_steps):\n",
        "            z = tf.random.normal((self.batch_size, self.latent_dim))\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                graph_generated = self.generator(z, training=True)\n",
        "                loss = self._loss_generator(graph_generated)\n",
        "\n",
        "                grads = tape.gradient(loss, self.generator.trainable_weights)\n",
        "                self.optimizer_generator.apply_gradients(\n",
        "                    zip(grads, self.generator.trainable_weights)\n",
        "                )\n",
        "                self.metric_generator.update_state(loss)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def _loss_discriminator(self, graph_real, graph_generated):\n",
        "        logits_real = self.discriminator(graph_real, training=True)\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        loss = tf.reduce_mean(logits_generated) - tf.reduce_mean(logits_real)\n",
        "        loss_gp = self._gradient_penalty(graph_real, graph_generated)\n",
        "        return loss + loss_gp * self.gp_weight\n",
        "\n",
        "    def _loss_generator(self, graph_generated):\n",
        "        logits_generated = self.discriminator(graph_generated, training=True)\n",
        "        return -tf.reduce_mean(logits_generated)\n",
        "\n",
        "    def _gradient_penalty(self, graph_real, graph_generated):\n",
        "        # Unpack graphs\n",
        "        adjacency_real, features_real = graph_real\n",
        "        adjacency_generated, features_generated = graph_generated\n",
        "\n",
        "        # Generate interpolated graphs (adjacency_interp and features_interp)\n",
        "        alpha = tf.random.uniform([self.batch_size])\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1, 1))\n",
        "        adjacency_interp = (adjacency_real * alpha) + (1 - alpha) * adjacency_generated\n",
        "        alpha = tf.reshape(alpha, (self.batch_size, 1, 1))\n",
        "        features_interp = (features_real * alpha) + (1 - alpha) * features_generated\n",
        "\n",
        "        # Compute the logits of interpolated graphs\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(adjacency_interp)\n",
        "            tape.watch(features_interp)\n",
        "            logits = self.discriminator(\n",
        "                [adjacency_interp, features_interp], training=True\n",
        "            )\n",
        "\n",
        "        # Compute the gradients with respect to the interpolated graphs\n",
        "        grads = tape.gradient(logits, [adjacency_interp, features_interp])\n",
        "        # Compute the gradient penalty\n",
        "        grads_adjacency_penalty = (1 - tf.norm(grads[0], axis=1)) ** 2\n",
        "        grads_features_penalty = (1 - tf.norm(grads[1], axis=2)) ** 2\n",
        "        return tf.reduce_mean(\n",
        "            tf.reduce_mean(grads_adjacency_penalty, axis=(-2, -1))\n",
        "            + tf.reduce_mean(grads_features_penalty, axis=(-1))\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmNpJXO9lIM3"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "To save time (if run on a CPU), we'll only train the model for 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Adjacency shape:\", adjacency_tensor.shape)\n",
        "print(\"Feature shape:\", feature_tensor.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpiV0k3DqK48",
        "outputId": "4ca3a509-0360-4a1d-a1ba-f61e5d551800"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjacency shape: (13389, 5, 9, 9)\n",
            "Feature shape: (13389, 9, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LATENT_DIM   = 32\n",
        "NUM_ATOMS    = 9\n",
        "BOND_DIM     = 5      # 👈 changed from 4 → 5\n",
        "ATOM_DIM     = 5\n"
      ],
      "metadata": {
        "id": "AaaZTB6BqSOJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = GraphGenerator(\n",
        "    dense_units=[128, 256, 512],\n",
        "    dropout_rate=0.2,\n",
        "    latent_dim=LATENT_DIM,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "\n",
        "critic = GraphCritic(\n",
        "    dense_units=[512, 256, 128],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n"
      ],
      "metadata": {
        "id": "jL0qDx93qUhw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critic = GraphCritic(\n",
        "    dense_units=[512, 256, 128],\n",
        "    dropout_rate=0.2,\n",
        "    adjacency_shape=(BOND_DIM, NUM_ATOMS, NUM_ATOMS),\n",
        "    feature_shape=(NUM_ATOMS, ATOM_DIM),\n",
        ")\n",
        "print(\"✅ New Critic input shape:\", critic.input_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urYqXzHSqlCf",
        "outputId": "bacce7c0-c277-4b97-8bec-031a4848ec0a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ New Critic input shape: [(None, 5, 9, 9), (None, 9, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ MUST recreate WGAN after critic is rebuilt\n",
        "wgan = GraphWGAN(generator, critic, discriminator_steps=1)\n",
        "\n",
        "wgan.compile(\n",
        "    optimizer_generator=keras.optimizers.Adam(5e-4),\n",
        "    optimizer_discriminator=keras.optimizers.Adam(5e-4),\n",
        ")\n"
      ],
      "metadata": {
        "id": "6efWX8-4qwcs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"WGAN critic input shape:\", wgan.discriminator.input_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHYUP1g5qz2B",
        "outputId": "774ea399-55ef-43a0-be6a-24c44b4d2d4a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WGAN critic input shape: [(None, 5, 9, 9), (None, 9, 5)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert adjacency_tensor.shape[1:] == wgan.discriminator.input_shape[0][1:], \"Adjacency mismatch!\"\n",
        "assert feature_tensor.shape[1:] == wgan.discriminator.input_shape[1][1:], \"Feature mismatch!\"\n",
        "print(\"✅ All shapes match. Ready to train!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXWC-ZP4q4nc",
        "outputId": "8674f9f7-862f-41b4-cf93-3cd5d3d51862"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ All shapes match. Ready to train!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wgan.fit([adjacency_tensor, feature_tensor], epochs=10, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STV-Omekq_BU",
        "outputId": "467cfac7-0775-4465-94ee-0834afc92020"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 17ms/step - loss: 0.0000e+00 - loss_dis: -26.8103 - loss_gen: -9.2012\n",
            "Epoch 2/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -5.7362 - loss_gen: -6.0252\n",
            "Epoch 3/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -5.0082 - loss_gen: -0.0828\n",
            "Epoch 4/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -5.2498 - loss_gen: -10.7313\n",
            "Epoch 5/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -5.5550 - loss_gen: -9.4205\n",
            "Epoch 6/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0000e+00 - loss_dis: -5.1220 - loss_gen: -7.0705\n",
            "Epoch 7/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -4.7473 - loss_gen: -8.7837\n",
            "Epoch 8/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -4.4540 - loss_gen: -2.3979\n",
            "Epoch 9/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0000e+00 - loss_dis: -5.0746 - loss_gen: -7.3026\n",
            "Epoch 10/10\n",
            "\u001b[1m837/837\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0000e+00 - loss_dis: -4.7052 - loss_gen: -11.5252\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7efd7dd5e330>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "adj_train, adj_val, feat_train, feat_val = train_test_split(\n",
        "    adjacency_tensor, feature_tensor, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train adjacency:\", adj_train.shape)\n",
        "print(\"Val adjacency:\", adj_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrXSnrYEreVT",
        "outputId": "0b1268bd-86ca-4473-dbcd-a669cda653cb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train adjacency: (10711, 5, 9, 9)\n",
            "Val adjacency: (2678, 5, 9, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((adj_train, feat_train)).shuffle(1024).batch(BATCH_SIZE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((adj_val, feat_val)).batch(BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "oo1gCGP1reSD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_adj, real_feat = inputs\n",
        "self.batch_size = tf.shape(real_adj)[0]\n",
        "graph_real = [real_adj, real_feat]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "-NITSZFIr1TR",
        "outputId": "345abf5a-ad52-4685-d1ff-9e8d890b2791"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'inputs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1061899427.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreal_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_adj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgraph_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreal_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    train_d_loss, train_g_loss = [], []\n",
        "\n",
        "    # ---- Training Loop ----\n",
        "    for real_adj, real_feat in train_ds:\n",
        "        losses = wgan.train_on_batch([real_adj, real_feat])\n",
        "        train_d_loss.append(losses[1])  # discriminator loss\n",
        "        train_g_loss.append(losses[2])  # generator loss\n",
        "\n",
        "    # ---- Validation Loop ----\n",
        "    val_d_loss, val_g_loss = [], []\n",
        "    for val_adj, val_feat in val_ds:\n",
        "        # Generate fake graphs\n",
        "        noise = tf.random.normal([val_adj.shape[0], LATENT_DIM])\n",
        "        fake_adj, fake_feat = generator(noise, training=False)\n",
        "\n",
        "        # Critic outputs\n",
        "        real_logits = critic([val_adj, val_feat], training=False)\n",
        "        fake_logits = critic([fake_adj, fake_feat], training=False)\n",
        "\n",
        "        # WGAN losses\n",
        "        d_loss_val = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
        "        g_loss_val = -tf.reduce_mean(fake_logits)\n",
        "\n",
        "        val_d_loss.append(d_loss_val.numpy())\n",
        "        val_g_loss.append(g_loss_val.numpy())\n",
        "\n",
        "    print(\n",
        "        f\"Train D: {np.mean(train_d_loss):.4f}, Train G: {np.mean(train_g_loss):.4f} | \"\n",
        "        f\"Val D: {np.mean(val_d_loss):.4f}, Val G: {np.mean(val_g_loss):.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cLsX2uTRrePj",
        "outputId": "abb1b466-e424-4f1c-b876-eb26ae323b92"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Shapes must be equal rank, but are 4 and 3\n\tFrom merging shape 0 with other shapes. for '{{node Shape/packed}} = Pack[N=2, T=DT_FLOAT, axis=0](data, data_1)' with input shapes: [16,5,9,9], [16,9,5].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2613746886.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# ---- Training Loop ----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreal_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_feat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreal_adj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_d_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# discriminator loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_g_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# generator loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 ):\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    116\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1910002604.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mgraph_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Train the discriminator for one or more steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Shapes must be equal rank, but are 4 and 3\n\tFrom merging shape 0 with other shapes. for '{{node Shape/packed}} = Pack[N=2, T=DT_FLOAT, axis=0](data, data_1)' with input shapes: [16,5,9,9], [16,9,5]."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yev6wnJlreNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "pzBlgGPrlIM3",
        "outputId": "4c399dbf-fb00-4815-dc98-fbaa4acdffcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 4, 9, 9), found shape=(None, 5, 9, 9)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1300571758.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0madjacency_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1910002604.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mgraph_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1910002604.py\u001b[0m in \u001b[0;36m_loss_discriminator\u001b[0;34m(self, graph_real, graph_generated)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_loss_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_generated\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mlogits_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mlogits_generated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_generated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_generated\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 4, 9, 9), found shape=(None, 5, 9, 9)"
          ]
        }
      ],
      "source": [
        "wgan = GraphWGAN(generator, discriminator, discriminator_steps=1)\n",
        "\n",
        "wgan.compile(\n",
        "    optimizer_generator=keras.optimizers.Adam(5e-4),\n",
        "    optimizer_discriminator=keras.optimizers.Adam(5e-4),\n",
        ")\n",
        "\n",
        "wgan.fit([adjacency_tensor, feature_tensor], epochs=10, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CHAT CODE"
      ],
      "metadata": {
        "id": "CL-89qkFsj2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# ----------------------------\n",
        "# Hyperparameters (match your data)\n",
        "# ----------------------------\n",
        "LATENT_DIM   = 32\n",
        "NUM_ATOMS    = 9\n",
        "BOND_DIM     = 5    # ✅ must match adjacency_tensor.shape[1]\n",
        "ATOM_DIM     = 5    # ✅ must match feature_tensor.shape[2]\n",
        "EPOCHS       = 10\n",
        "BATCH_SIZE   = 16\n",
        "LAMBDA_GP    = 10.0\n",
        "\n",
        "# ----------------------------\n",
        "# Generator\n",
        "# ----------------------------\n",
        "def GraphGenerator(dense_units, dropout_rate, latent_dim, adjacency_shape, feature_shape):\n",
        "    z = layers.Input(shape=(latent_dim,))\n",
        "    x = z\n",
        "    for units in dense_units:\n",
        "        x = layers.Dense(units, activation=\"tanh\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "\n",
        "    # Adjacency tensor\n",
        "    x_adj = layers.Dense(int(tf.reduce_prod(adjacency_shape)))(x)\n",
        "    x_adj = layers.Reshape(adjacency_shape)(x_adj)\n",
        "    x_adj = layers.Lambda(lambda t: (t + tf.transpose(t, perm=[0, 1, 3, 2])) / 2)(x_adj)\n",
        "    x_adj = layers.Softmax(axis=1)(x_adj)\n",
        "\n",
        "    # Feature tensor\n",
        "    x_feat = layers.Dense(int(tf.reduce_prod(feature_shape)))(x)\n",
        "    x_feat = layers.Reshape(feature_shape)(x_feat)\n",
        "    x_feat = layers.Softmax(axis=2)(x_feat)\n",
        "\n",
        "    return keras.Model(inputs=z, outputs=[x_adj, x_feat], name=\"Generator\")\n",
        "\n",
        "# ----------------------------\n",
        "# Critic (Discriminator)\n",
        "# ----------------------------\n",
        "def GraphCritic(dense_units, dropout_rate, adjacency_shape, feature_shape):\n",
        "    adj_input = layers.Input(shape=adjacency_shape)\n",
        "    feat_input = layers.Input(shape=feature_shape)\n",
        "    x = layers.Concatenate()([layers.Flatten()(adj_input), layers.Flatten()(feat_input)])\n",
        "    for units in dense_units:\n",
        "        x = layers.Dense(units, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    out = layers.Dense(1)(x)\n",
        "    return keras.Model(inputs=[adj_input, feat_input], outputs=out, name=\"Critic\")\n",
        "\n",
        "# ----------------------------\n",
        "# Instantiate models\n",
        "# ----------------------------\n",
        "generator = GraphGenerator([128, 256, 512], 0.2, LATENT_DIM, (BOND_DIM, NUM_ATOMS, NUM_ATOMS), (NUM_ATOMS, ATOM_DIM))\n",
        "critic = GraphCritic([512, 256, 128], 0.2, (BOND_DIM, NUM_ATOMS, NUM_ATOMS), (NUM_ATOMS, ATOM_DIM))\n",
        "\n",
        "g_optimizer = keras.optimizers.Adam(5e-4)\n",
        "d_optimizer = keras.optimizers.Adam(5e-4)\n",
        "\n",
        "# ----------------------------\n",
        "# Train/Validation split\n",
        "# ----------------------------\n",
        "adj_train, adj_val, feat_train, feat_val = train_test_split(\n",
        "    adjacency_tensor, feature_tensor, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((adj_train, feat_train)).shuffle(1024).batch(BATCH_SIZE)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((adj_val, feat_val)).batch(BATCH_SIZE)\n",
        "\n",
        "# ----------------------------\n",
        "# Gradient penalty (WGAN-GP)\n",
        "# ----------------------------\n",
        "def gradient_penalty(real, fake):\n",
        "    alpha = tf.random.uniform([real[0].shape[0], 1, 1, 1], 0.0, 1.0)\n",
        "    interpolated_adj = alpha * real[0] + (1 - alpha) * fake[0]\n",
        "    interpolated_feat = alpha[:, 0, 0, 0:1] * real[1] + (1 - alpha[:, 0, 0, 0:1]) * fake[1]\n",
        "    with tf.GradientTape() as gp_tape:\n",
        "        gp_tape.watch([interpolated_adj, interpolated_feat])\n",
        "        pred = critic([interpolated_adj, interpolated_feat], training=True)\n",
        "    grads = gp_tape.gradient(pred, [interpolated_adj, interpolated_feat])\n",
        "    slopes = tf.sqrt(tf.reduce_sum(tf.square(grads[0])) + tf.reduce_sum(tf.square(grads[1])))\n",
        "    return tf.square(slopes - 1.0)\n",
        "\n",
        "\n",
        "def gradient_penalty(real, fake):\n",
        "    real_adj, real_feat = real\n",
        "    fake_adj, fake_feat = fake\n",
        "    batch_size = tf.shape(real_adj)[0]\n",
        "\n",
        "    # separate alpha for adjacency (4D) and feature (3D)\n",
        "    alpha_adj = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
        "    alpha_feat = tf.random.uniform([batch_size, 1, 1], 0.0, 1.0)\n",
        "\n",
        "    interpolated_adj = alpha_adj * real_adj + (1 - alpha_adj) * fake_adj\n",
        "    interpolated_feat = alpha_feat * real_feat + (1 - alpha_feat) * fake_feat\n",
        "\n",
        "    with tf.GradientTape() as gp_tape:\n",
        "        gp_tape.watch([interpolated_adj, interpolated_feat])\n",
        "        pred = critic([interpolated_adj, interpolated_feat], training=True)\n",
        "\n",
        "    grads = gp_tape.gradient(pred, [interpolated_adj, interpolated_feat])\n",
        "\n",
        "    slopes_adj = tf.sqrt(tf.reduce_sum(tf.square(grads[0]), axis=[1, 2, 3]))\n",
        "    slopes_feat = tf.sqrt(tf.reduce_sum(tf.square(grads[1]), axis=[1, 2]))\n",
        "\n",
        "    slopes = (slopes_adj + slopes_feat) / 2.0\n",
        "    return tf.reduce_mean(tf.square(slopes - 1.0))\n",
        "\n",
        "# ----------------------------\n",
        "# Training Loop\n",
        "# ----------------------------\n",
        "for epoch in range(EPOCHS):\n",
        "    train_d_losses, train_g_losses = [], []\n",
        "    for real_adj, real_feat in train_ds:\n",
        "        batch_size = tf.shape(real_adj)[0]\n",
        "\n",
        "        # ---- Train Critic ----\n",
        "        noise = tf.random.normal([batch_size, LATENT_DIM])\n",
        "        fake_adj, fake_feat = generator(noise, training=True)\n",
        "\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            logits_real = critic([real_adj, real_feat], training=True)\n",
        "            logits_fake = critic([fake_adj, fake_feat], training=True)\n",
        "            d_loss = tf.reduce_mean(logits_fake) - tf.reduce_mean(logits_real)\n",
        "            gp = gradient_penalty([real_adj, real_feat], [fake_adj, fake_feat])\n",
        "            d_loss += LAMBDA_GP * gp\n",
        "\n",
        "        d_grads = d_tape.gradient(d_loss, critic.trainable_variables)\n",
        "        d_optimizer.apply_gradients(zip(d_grads, critic.trainable_variables))\n",
        "        train_d_losses.append(d_loss.numpy())\n",
        "\n",
        "        # ---- Train Generator ----\n",
        "        noise = tf.random.normal([batch_size, LATENT_DIM])\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            fake_adj, fake_feat = generator(noise, training=True)\n",
        "            logits_fake = critic([fake_adj, fake_feat], training=True)\n",
        "            g_loss = -tf.reduce_mean(logits_fake)\n",
        "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
        "        g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
        "        train_g_losses.append(g_loss.numpy())\n",
        "\n",
        "    # ----------------------------\n",
        "    # Validation losses\n",
        "    # ----------------------------\n",
        "    val_d_losses, val_g_losses = [], []\n",
        "    for val_adj, val_feat in val_ds:\n",
        "        noise = tf.random.normal([val_adj.shape[0], LATENT_DIM])\n",
        "        fake_adj, fake_feat = generator(noise, training=False)\n",
        "        val_logits_real = critic([val_adj, val_feat], training=False)\n",
        "        val_logits_fake = critic([fake_adj, fake_feat], training=False)\n",
        "\n",
        "        d_val = tf.reduce_mean(val_logits_fake) - tf.reduce_mean(val_logits_real)\n",
        "        g_val = -tf.reduce_mean(val_logits_fake)\n",
        "        val_d_losses.append(d_val.numpy())\n",
        "        val_g_losses.append(g_val.numpy())\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "        f\"Train D: {np.mean(train_d_losses):.4f}, Train G: {np.mean(train_g_losses):.4f} | \"\n",
        "        f\"Val D: {np.mean(val_d_losses):.4f}, Val G: {np.mean(val_g_losses):.4f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mnKw-Zqsl9u",
        "outputId": "da0eb376-7cda-41cd-afcb-f2d82052a78b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train D: -2.7225, Train G: 0.3014 | Val D: -1.4401, Val G: 3.3781\n",
            "Epoch 2/10 | Train D: -1.6565, Train G: 0.4190 | Val D: -2.2318, Val G: 0.9904\n",
            "Epoch 3/10 | Train D: -1.7539, Train G: -0.0864 | Val D: -1.7513, Val G: 0.5323\n",
            "Epoch 4/10 | Train D: -1.6684, Train G: -0.1705 | Val D: -1.7450, Val G: -0.9527\n",
            "Epoch 5/10 | Train D: -1.5357, Train G: -0.9348 | Val D: -1.5914, Val G: -1.3434\n",
            "Epoch 6/10 | Train D: -1.5747, Train G: -0.4822 | Val D: -1.8393, Val G: 0.1612\n",
            "Epoch 7/10 | Train D: -1.3954, Train G: -0.8700 | Val D: -1.6065, Val G: 0.5886\n",
            "Epoch 8/10 | Train D: -1.5202, Train G: -0.5164 | Val D: -1.8218, Val G: 0.0433\n",
            "Epoch 9/10 | Train D: -1.5706, Train G: -0.3720 | Val D: -1.7462, Val G: -1.4560\n",
            "Epoch 10/10 | Train D: -1.4514, Train G: -0.5962 | Val D: -1.6662, Val G: -1.2056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "EPOCHS = 30\n",
        "patience = 5  # stop if Val G doesn't improve for 5 epochs\n",
        "best_val_g = float(\"inf\")\n",
        "bad_epochs = 0\n",
        "\n",
        "history = {\"train_d\": [], \"train_g\": [], \"val_d\": [], \"val_g\": [], \"wasserstein\": []}\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_d_losses, train_g_losses = [], []\n",
        "\n",
        "    # ----------------------------\n",
        "    # Train Loop\n",
        "    # ----------------------------\n",
        "    for real_adj, real_feat in train_ds:\n",
        "        batch_size = tf.shape(real_adj)[0]\n",
        "\n",
        "        # Train critic\n",
        "        noise = tf.random.normal([batch_size, LATENT_DIM])\n",
        "        fake_adj, fake_feat = generator(noise, training=True)\n",
        "\n",
        "        with tf.GradientTape() as d_tape:\n",
        "            logits_real = critic([real_adj, real_feat], training=True)\n",
        "            logits_fake = critic([fake_adj, fake_feat], training=True)\n",
        "            d_loss = tf.reduce_mean(logits_fake) - tf.reduce_mean(logits_real)\n",
        "            gp = gradient_penalty([real_adj, real_feat], [fake_adj, fake_feat])\n",
        "            d_loss += LAMBDA_GP * gp\n",
        "\n",
        "        d_grads = d_tape.gradient(d_loss, critic.trainable_variables)\n",
        "        d_optimizer.apply_gradients(zip(d_grads, critic.trainable_variables))\n",
        "        train_d_losses.append(d_loss.numpy())\n",
        "\n",
        "        # Train generator\n",
        "        noise = tf.random.normal([batch_size, LATENT_DIM])\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            fake_adj, fake_feat = generator(noise, training=True)\n",
        "            logits_fake = critic([fake_adj, fake_feat], training=True)\n",
        "            g_loss = -tf.reduce_mean(logits_fake)\n",
        "        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)\n",
        "        g_optimizer.apply_gradients(zip(g_grads, generator.trainable_variables))\n",
        "        train_g_losses.append(g_loss.numpy())\n",
        "\n",
        "    # ----------------------------\n",
        "    # Validation Loop\n",
        "    # ----------------------------\n",
        "    val_d_losses, val_g_losses, wasserstein_vals = [], [], []\n",
        "    for val_adj, val_feat in val_ds:\n",
        "        noise = tf.random.normal([val_adj.shape[0], LATENT_DIM])\n",
        "        fake_adj, fake_feat = generator(noise, training=False)\n",
        "        val_logits_real = critic([val_adj, val_feat], training=False)\n",
        "        val_logits_fake = critic([fake_adj, fake_feat], training=False)\n",
        "\n",
        "        d_val = tf.reduce_mean(val_logits_fake) - tf.reduce_mean(val_logits_real)\n",
        "        g_val = -tf.reduce_mean(val_logits_fake)\n",
        "        wasserstein = tf.reduce_mean(val_logits_real) - tf.reduce_mean(val_logits_fake)\n",
        "\n",
        "        val_d_losses.append(d_val.numpy())\n",
        "        val_g_losses.append(g_val.numpy())\n",
        "        wasserstein_vals.append(wasserstein.numpy())\n",
        "\n",
        "    # ----------------------------\n",
        "    # Epoch summary\n",
        "    # ----------------------------\n",
        "    tD = np.mean(train_d_losses)\n",
        "    tG = np.mean(train_g_losses)\n",
        "    vD = np.mean(val_d_losses)\n",
        "    vG = np.mean(val_g_losses)\n",
        "    W  = np.mean(wasserstein_vals)\n",
        "\n",
        "    history[\"train_d\"].append(tD)\n",
        "    history[\"train_g\"].append(tG)\n",
        "    history[\"val_d\"].append(vD)\n",
        "    history[\"val_g\"].append(vG)\n",
        "    history[\"wasserstein\"].append(W)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
        "        f\"Train D: {tD:.4f}, Train G: {tG:.4f} | \"\n",
        "        f\"Val D: {vD:.4f}, Val G: {vG:.4f} | W: {W:.4f}\"\n",
        "    )\n",
        "\n",
        "    # ----------------------------\n",
        "    # Early stopping check\n",
        "    # ----------------------------\n",
        "    if vG < best_val_g:\n",
        "        best_val_g = vG\n",
        "        bad_epochs = 0\n",
        "        generator.save_weights(\"best_generator.h5\")\n",
        "        critic.save_weights(\"best_critic.h5\")\n",
        "    else:\n",
        "        bad_epochs += 1\n",
        "        print(f\"⚠️ Validation G did not improve for {bad_epochs} epoch(s)\")\n",
        "        if bad_epochs >= patience:\n",
        "            print(\"🛑 Early stopping triggered – possible overfitting.\")\n",
        "            break\n",
        "\n",
        "# ----------------------------\n",
        "# Plotting loss curves\n",
        "# ----------------------------\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history[\"train_g\"], label=\"Train G\")\n",
        "plt.plot(history[\"val_g\"], label=\"Val G\")\n",
        "plt.axhline(0, color='gray', linestyle='--', linewidth=0.7)\n",
        "plt.legend(); plt.title(\"Generator Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history[\"train_d\"], label=\"Train D\")\n",
        "plt.plot(history[\"val_d\"], label=\"Val D\")\n",
        "plt.legend(); plt.title(\"Critic Loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(history[\"wasserstein\"], label=\"Wasserstein Distance\")\n",
        "plt.legend(); plt.title(\"Wasserstein Estimate (Higher = Better)\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"W\"); plt.show()\n"
      ],
      "metadata": {
        "id": "9cxaGkFS1N8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icc6pQAHlIM3"
      },
      "source": [
        "## Sample novel molecules with the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM6wZCAXlIM4"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample(generator, batch_size):\n",
        "    z = tf.random.normal((batch_size, LATENT_DIM))\n",
        "    graph = generator.predict(z)\n",
        "    # obtain one-hot encoded adjacency tensor\n",
        "    adjacency = tf.argmax(graph[0], axis=1)\n",
        "    adjacency = tf.one_hot(adjacency, depth=BOND_DIM, axis=1)\n",
        "    # Remove potential self-loops from adjacency\n",
        "    adjacency = tf.linalg.set_diag(adjacency, tf.zeros(tf.shape(adjacency)[:-1]))\n",
        "    # obtain one-hot encoded feature tensor\n",
        "    features = tf.argmax(graph[1], axis=2)\n",
        "    features = tf.one_hot(features, depth=ATOM_DIM, axis=2)\n",
        "    return [\n",
        "        graph_to_molecule([adjacency[i].numpy(), features[i].numpy()])\n",
        "        for i in range(batch_size)\n",
        "    ]\n",
        "\n",
        "\n",
        "molecules = sample(wgan.generator, batch_size=48)\n",
        "\n",
        "MolsToGridImage(\n",
        "    [m for m in molecules if m is not None][:25], molsPerRow=5, subImgSize=(150, 150)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE7-xZYhlIM4"
      },
      "source": [
        "## Concluding thoughts\n",
        "\n",
        "**Inspecting the results**. Ten epochs of training seemed enough to generate some decent\n",
        "looking molecules! Notice, in contrast to the\n",
        "[MolGAN paper](https://arxiv.org/abs/1805.11973), the uniqueness of the generated\n",
        "molecules in this tutorial seems really high, which is great!\n",
        "\n",
        "**What we've learned, and prospects**. In this tutorial, a generative model for molecular\n",
        "graphs was successfully implemented, which allowed us to generate novel molecules. In the\n",
        "future, it would be interesting to implement generative models that can modify existing\n",
        "molecules (for instance, to optimize solubility or protein-binding of an existing\n",
        "molecule). For that however, a reconstruction loss would likely be needed, which is\n",
        "tricky to implement as there's no easy and obvious way to compute similarity between two\n",
        "molecular graphs.\n",
        "\n",
        "Example available on HuggingFace\n",
        "\n",
        "| Trained Model | Demo |\n",
        "| :--: | :--: |\n",
        "| [![Generic badge](https://img.shields.io/badge/%F0%9F%A4%97%20Model-wgan%20graphs-black.svg)](https://huggingface.co/keras-io/wgan-molecular-graphs) | [![Generic badge](https://img.shields.io/badge/%F0%9F%A4%97%20Spaces-wgan%20graphs-black.svg)](https://huggingface.co/spaces/keras-io/Generating-molecular-graphs-by-WGAN-GP) |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "wgan-graphs",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}